{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_lr_scheduler",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aum4Cq3PDD6k"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za0XiHlJPJgX"
      },
      "source": [
        "num_classes = 10\r\n",
        "learning_rate = 0.01\r\n",
        "batch_size = 128\r\n",
        "num_epochs = 50"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FI5hSuAPP9u"
      },
      "source": [
        "model = nn.Sequential(\r\n",
        "    nn.Linear(784, 50),\r\n",
        "    nn.ReLU(),\r\n",
        "    nn.Linear(50, num_classes)\r\n",
        ").to(device)\r\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yvC-m8zP0Z-",
        "outputId": "c8fa3fe9-f8ab-468f-9047-92761571382e"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\r\n",
        "!tar -zxvf MNIST.tar.gz\r\n",
        "\r\n",
        "from torchvision.datasets import MNIST\r\n",
        "from torchvision import transforms\r\n",
        "\r\n",
        "train_dataset = MNIST('./', download=True,\r\n",
        "transform=transforms.Compose([transforms.ToTensor(),]),\r\n",
        " train=True)\r\n",
        "\r\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-17 14:23:38--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-17 14:23:38--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.4’\n",
            "\n",
            "MNIST.tar.gz.4          [      <=>           ]  33.20M  29.9MB/s    in 1.1s    \n",
            "\n",
            "2021-03-17 14:23:39 (29.9 MB/s) - ‘MNIST.tar.gz.4’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEhj5j6CQSnV"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\r\n",
        "    optimizer, factor=0.1, patience=5, verbose=True\r\n",
        ") # 5epoch이 넘도록 loss가 줄어들지 않으면 Learning rate를 10%줄인다. "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqdB5Z-PTdjH",
        "outputId": "e90801d8-7408-4d15-b6c1-04c451b9ee72"
      },
      "source": [
        "for epoch in range(1, num_epochs):\r\n",
        "    losses = []\r\n",
        "\r\n",
        "    for idx, (data, targets) in enumerate(train_loader):\r\n",
        "        data = data.reshape(data.shape[0], -1)\r\n",
        "        data = data.to(device)\r\n",
        "        targets = targets.to(device)\r\n",
        "\r\n",
        "        scores = model(data)\r\n",
        "        loss = criterion(scores, targets)\r\n",
        "        losses.append(loss.item())\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        optimizer.step()\r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "\r\n",
        "    mean_loss = sum(losses) / len(losses)\r\n",
        "\r\n",
        "    scheduler.step(mean_loss)  # mean_loss로 lr을 결정\r\n",
        "    print(f\"Epoch: {epoch} | Loss: {mean_loss:.5f}\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Loss: 0.18830\n",
            "Epoch: 2 | Loss: 0.18599\n",
            "Epoch: 3 | Loss: 0.18741\n",
            "Epoch: 4 | Loss: 0.18568\n",
            "Epoch: 5 | Loss: 0.18756\n",
            "Epoch: 6 | Loss: 0.18373\n",
            "Epoch: 7 | Loss: 0.18585\n",
            "Epoch: 8 | Loss: 0.18695\n",
            "Epoch: 9 | Loss: 0.18665\n",
            "Epoch: 10 | Loss: 0.18514\n",
            "Epoch: 11 | Loss: 0.18497\n",
            "Epoch   160: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch: 12 | Loss: 0.18707\n",
            "Epoch: 13 | Loss: 0.16808\n",
            "Epoch: 14 | Loss: 0.16494\n",
            "Epoch: 15 | Loss: 0.16427\n",
            "Epoch: 16 | Loss: 0.16406\n",
            "Epoch: 17 | Loss: 0.16382\n",
            "Epoch: 18 | Loss: 0.16363\n",
            "Epoch: 19 | Loss: 0.16347\n",
            "Epoch: 20 | Loss: 0.16325\n",
            "Epoch: 21 | Loss: 0.16302\n",
            "Epoch: 22 | Loss: 0.16289\n",
            "Epoch: 23 | Loss: 0.16282\n",
            "Epoch: 24 | Loss: 0.16285\n",
            "Epoch: 25 | Loss: 0.16255\n",
            "Epoch: 26 | Loss: 0.16258\n",
            "Epoch: 27 | Loss: 0.16263\n",
            "Epoch: 28 | Loss: 0.16248\n",
            "Epoch: 29 | Loss: 0.16247\n",
            "Epoch: 30 | Loss: 0.16225\n",
            "Epoch: 31 | Loss: 0.16221\n",
            "Epoch: 32 | Loss: 0.16228\n",
            "Epoch: 33 | Loss: 0.16215\n",
            "Epoch: 34 | Loss: 0.16214\n",
            "Epoch: 35 | Loss: 0.16209\n",
            "Epoch: 36 | Loss: 0.16183\n",
            "Epoch: 37 | Loss: 0.16184\n",
            "Epoch: 38 | Loss: 0.16204\n",
            "Epoch: 39 | Loss: 0.16192\n",
            "Epoch: 40 | Loss: 0.16171\n",
            "Epoch: 41 | Loss: 0.16186\n",
            "Epoch: 42 | Loss: 0.16174\n",
            "Epoch: 43 | Loss: 0.16182\n",
            "Epoch: 44 | Loss: 0.16171\n",
            "Epoch: 45 | Loss: 0.16138\n",
            "Epoch: 46 | Loss: 0.16168\n",
            "Epoch: 47 | Loss: 0.16142\n",
            "Epoch: 48 | Loss: 0.16150\n",
            "Epoch: 49 | Loss: 0.16155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaUkBD6kU-SI",
        "outputId": "a9969e34-2290-4560-eedc-8721a17200fc"
      },
      "source": [
        "def check_accuracy(loader, model):\r\n",
        "    num_correct = 0\r\n",
        "    num_samples = 0\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.reshape(x.shape[0], -1)\r\n",
        "            x = x.to(device)\r\n",
        "            y = y.to(device)\r\n",
        "            \r\n",
        "            scores = model(x)\r\n",
        "            _, predicted = scores.max(1)\r\n",
        "            num_correct += (predicted == y).sum()\r\n",
        "            num_samples += predicted.size(0)\r\n",
        "\r\n",
        "        print(\r\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\r\n",
        "        )\r\n",
        "\r\n",
        "    model.train()\r\n",
        "\r\n",
        "check_accuracy(train_loader, model)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got 57284 / 60000 with accuracy 95.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcIHzpxgnlFk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}